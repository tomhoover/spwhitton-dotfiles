#!/usr/bin/perl

# Cold (offline) backups & other elements in a weekly maintenance routine

# The idea is that if this script dies it can be safely be re-run from the beginning

# Note that each backup drive needs a unique filesystem label!

use strict;
use warnings;
use lib "$ENV{HOME}/lib/perl5";
no warnings "experimental::smartmatch";

use Dpkg::Version;
use Term::UI;
use ShellSequence;
use ScriptStatus;
use File::Grep "fgrep";
use File::Basename;
use File::chdir;
use Capture::Tiny qw/capture_merged capture/;
use List::MoreUtils "apply";
use File::Spec::Functions "rel2abs";
use Sys::Hostname;

my $seq = ShellSequence->new();
my $term = Term::ReadLine->new('brand');
my $host = hostname;

# ---- config

our @src_exceptions = qw/hscripts/;
our $git = "/srv/git/repositories";

# since I am now using exclusively gcrypt's rsync mode, I do not need
# to detect whether a repo is a gcrypt repo before attempting to back
# it up.  Note that git-remote-gcrypt has a --check option for doing
# this, though
our $gcrypt = "/srv/gcrypt";

# TODO determine whether a repo is an annex programmatically?
# advantage of manual list is that we can easily exclude rt.git and
# podcasts.git, where we don't want any content copied to the backup
# drive
my @annexes = qw/annex.git wikiannex.git dionysus.git/;

# ---- prep

chdir $ENV{HOME};
system "mount lib/athena 2>/dev/null" || 1;
my ($loc, $drive_name, $short_drive_name);

if (@ARGV) {
    $loc = rel2abs(shift @ARGV);
    die "$loc is not a directory" unless ( -d $loc );
    my @mountpoints = split /^/, `mount | cut -d' ' -f3`;
    @mountpoints = apply { $_ =~ s/^\s+|\s+$//g } @mountpoints;
    $drive_name = $loc;
    $short_drive_name = basename $drive_name;
    die "$loc is not a removable drive" unless ( $drive_name ~~ @mountpoints );

    if ( ! -d "$loc/gitbk" ) {
        status "it looks like you haven't backed up to this media before";
        my $create = $term->ask_yn(prompt => "Create a new backup repository at $loc/gitbk?");
        if ($create) {
            mkdir "$loc/gitbk"
              or die "couldn't create $loc/gitbk -- check permissions";
        } else {
            exit 1;
        }
    }
} else {
    status "you didn't specify a drive to perform a coldbkup to as a command";
    status "line argument to this script";
    exit unless $term->ask_yn(
                              prompt => "Continue sysmaint without coldbkup?",
                              default => 'y',
                             );
}

# ---- pre-backup cleanup tasks

$seq->add_should_zero("ls tmp");
$seq->add_should_zero("ssh athena ls tmp");
$seq->add_should_zero("ssh athena ls local/files/tmp");
$seq->add_should_zero("ls lib/athena/tmp");
$seq->run();

status "cleaning up ~/src";
# we retain orig tarballs
unlink glob "src/*.dsc";
unlink glob "src/*.diff.gz";
unlink glob "src/*.upload";
unlink glob "src/*.inmulti";
unlink glob "src/*.changes";
unlink glob "src/*.deb";
unlink glob "src/*.build";
unlink glob "src/*.buildinfo";
unlink glob "src/*.debian.tar.*";
unlink glob "src/*[0-9].tar.*"; # native package generated tarballs
system "clean-patch-queues -y";

while (42) {
    clean_orig_tars();
    my $output = capture_merged { find_dirty_src() };
    if (length $output) {
        status "the following files/repos in ~/src should be cleaned up:";
        print $output;
        my $again = $term->ask_yn(
                                  prompt => "Check for files in ~/src again?",
                                  default => 'y',
                                 );
        last unless $again;
    } else {
        last;
    }
}

# ---- standard backup procedure

# run a restow to catch if we need to run `mr adopt`
$seq->add_should_succeed("mr -ms restow");
$seq->add_should_succeed("mr -ms autoci");
# `mr -ms isclean` checks for stuff to be checked in ...
$seq->add_should_succeed("mr -ms isclean");
$seq->add_should_succeed("mr -s up");
$seq->add_should_succeed("mr -s push");
# ... then `mr -ms status` finds unpushed branches & stashes
$seq->add_should_zero("mr -ms status");

$seq->run();

# ---- backup to offline media ("coldbkup" was old script name)

# TODO error handling here: since we're not using $seq for everything
if ( defined $loc ) {

    # ---- github-backup
    {
        mkdir "$loc/gitbk/github" unless ( -d "$loc/gitbk/github" );
        local $CWD = "$loc/gitbk/github";
        $seq->add_should_succeed("github-backup spwhitton");
        $seq->run();
    }

    # ---- athena repos
    my $athena_git_repos = capture {
        system "ssh athena 'for d in $git/*.git $git/*/*.git; do echo \$d; done'";
    };
    my $athena_gcrypt_repos = capture {
        system "ssh athena 'for d in $gcrypt/*; do echo \$d; done'";
    };
    my @athena_git_repos = split /^/, $athena_git_repos;
    @athena_git_repos = apply { s|$git/|| } @athena_git_repos;
    my @athena_gcrypt_repos = split /^/, $athena_gcrypt_repos;
    @athena_gcrypt_repos = apply { s|$gcrypt/|| } @athena_gcrypt_repos;

    # Skip repos that only exist to prevent accidental pushes of
    # private data to a public repo
    my @skip = qw/doc.git annex.git athpriv.git podcasts.git priv.git rt.git/;

    foreach my $repo ( @athena_git_repos ) {
        $repo =~ s/\n//g;

        if ( $repo ~~ @skip ) {
            next;
        }

        backup_repo("git\@spwhitton.name:$repo", "athena");
    }

    foreach my $repo ( @athena_gcrypt_repos ) {
        $repo =~ s/\n//g;
        backup_repo("gcrypt::rsync://athena:/srv/git/$repo", "athena_gcrypt");
    }

    # ---- misc. repos

    # Debian packages I'm responsible for, and a few other Debian repos

    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/wiki.git", "alioth", "pkg-emacsen");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dh-elpa.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dh-make-elpa.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/yasnippet.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ebib.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-async.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-buttercup.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-highlight-indentation.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-noflet.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/epl.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/f-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/flx.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/flycheck.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/helm.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/let-alist.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/paredit-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/parsebib.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/perspective-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/pkg-info-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/popup-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/persp-projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/helm-projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/rainbow-delimiters.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/seq-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/s-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/shut-up.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/smex.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ws-butler.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/zenburn-emacs.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/aggressive-indent-mode.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ert-async-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/git-annex-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/debpaste-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/magit-annex.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/xml-rpc-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/wc-mode.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/deft.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/key-chord-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/paredit-everywhere.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/visual-regexp-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/pointback.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-openwith.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-world-time-mode.git", "alioth");

    backup_repo("https://anonscm.debian.org/git/pkg-mozext/classic-theme-restorer.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/keysnail.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/ublock-origin.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/y-u-no-validate.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/self-destructing-cookies.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/collab-maint/mairix.git", "alioth");

}

# TODO luksClose if necessary & umount
# system "sudo umount $loc";

# ---- remote system maintenance

# TODO put a flag file on athena so this only happens once per week
# or, better, just rework this so I ssh to athena and run sysmaint
# there

status "info: you can unmount & eject $loc";
exit unless $term->ask_yn(
                          prompt =>
                          "Backups complete.  Perform remote & local system maintainance?"
                         );

status "checking athena's storage";
system "ssh athena df -h";
my $disc_space_okay = $term->ask_yn(
                                    prompt => "Does athena have enough free disc space?",
                                    default => 'y',
                                   );
die "deal with athena's low free disc space" unless $disc_space_okay;

status "checking athena's uptime";
system "ssh athena uptime";
my $athena_rebooted = $term->ask_yn(
                                    prompt => "Was athena rebooted?",
                                    default => 'n',
                                   );
die "perform athena reboot procedure" if $athena_rebooted;

$seq->add_should_succeed("ssh -t athena 'sudo apt-get update && sudo apt-get upgrade && sudo apt-get autoremove && sudo apt-get autoclean'");

# ---- local system maintenance

# clean packages installed by mk-build-deps(1)
$seq->add_should_succeed("sudo aptitude remove '~n-build-deps\$'");

$seq->add_should_succeed("sudo apt-get update");
$seq->add_should_succeed("sudo apt-get upgrade");
$seq->add_should_succeed("sudo apt-get dist-upgrade");
$seq->add_should_succeed("sudo apt-get -y autoremove");

$seq->add_should_zero("mailq | grep -v 'Mail queue is empty'");
$seq->add_should_zero("ssh athena mailq | grep -v 'Mail queue is empty'");

$seq->run();

# ---- subroutines

sub clean_orig_tars {
    my $origs = {};
    foreach my $f ( glob "src/*.orig.tar.*" ) {
        $f =~ m/src\/([^_]*)_/;
        push @{$origs->{"$1"}}, $f;
    }
    sub orig_ver {
        $a =~ m/src\/[^_]*_([^_]*).orig/;
        my $ver_a = Dpkg::Version->new("$1");
        $b =~ m/src\/[^_]*_([^_]*).orig/;
        my $ver_b = Dpkg::Version->new("$1");
        $a cmp $b;
    }
    foreach my $pkg (keys %$origs) {
        my @origs = sort orig_ver @{$origs->{$pkg}};
        if ( -d "src/$pkg/.git" ) {
            if ( scalar @origs > 2 ) {
                @origs = splice @origs, 0, -2;
            } else {
                @origs = ();
            }
        }
        foreach my $orig ( @origs ) {
            unlink $orig;
        }
    }
}

# TODO src-unregister script to delete entry from ~/src/.mrconfig and nuke the repo

sub find_dirty_src {
    foreach my $f ( glob "src/*" ) {
        my $short = basename($f);
        unless ( (-f $f && $f =~ /orig\.tar/)
                 # also permit symlinks to orig tarballs
                 || (-l $f && $f =~ /orig\.tar/)
                 # also permit gbp orig tarballs
                 || ($f =~ /orig\.gbp\.tar/)
                 || $short ~~ @src_exceptions
                 || (-d "$f/.git"
                     && ((fgrep { /^\[$short\]$/ } "src/.mrconfig")
                         || (fgrep { /^\[\$HOME\/$f\]$/ } ".mrconfig")))) {
            if (-d "$f/.git") {
                local $CWD = $f;
                system "mr register >/dev/null";
                print "$f\n" if ($? >> 8 != 0);
            } else {
                print "$f\n";
            }
        }
    }
}

sub backup_repo {
    my ( $long, $dest, $rename ) = @_;
    my $short;

    # flush the command sequencer
    $seq->run();
    # third param is optional: do we need to rename it because
    # remote's name is too generic (e.g. 'wiki')?
    if ( defined $rename ) {
        $short = $rename;
    } else {
        if ( $long =~ m/^http/ ) {
            ( undef, $short ) = split /\/([^\/]+)$/, $long;
        } else {
            ( undef, $short ) = split /:([^:]+)$/, $long;
        }
        $short =~ s/\/srv\/git\///;
    }

    $short = "$short.git" unless $short =~ /\.git$/;
    my $vshort = basename $short;
    $dest = "$loc/gitbk/$dest";
    my $dir = "$dest/$short";
    status "backup source: $long";
    status "backup dest:   $dir";

    # first we have to determine whether it's an annex, as that will
    # affect the commands we run both to clone and to update
    # TODO determine this with a script?
    my $annex = 0;
    if ( $dest eq "$loc/gitbk/athena" && $vshort ~~ @annexes ) {
        $annex = 1;
    }

    if ( -e $dir ) {            # repo already backed up to this drive
        local $CWD = $dir;
        # TODO second disjunct in to allow for non-bare repos on
        # backup drive, e.g. gitbk/athena/annex on m3.  At present,
        # gitbk/athena/annex.git is a symlink to gitbk/athena/annex.
        # We should be able to handle this without the symlink, in
        # this script
        if ( -d "annex" || -d ".git/annex" ) {
            system "git config annex.diskreserve '2GB'";
            # TODO ask user before pairing since it's a guess
            if ( my $host_repo = find_host_annex($vshort) ) {
                status "pairing $short with $host_repo";
                local $CWD = $host_repo;
                system "git remote add $short_drive_name $dir 2>/dev/null" || 1;
                $seq->add_should_succeed("git annex sync --content $short_drive_name");
                $seq->run();
                # TODO now metadata sync with origin remote, if it exists
            } else {
                # TODO extend ShellSequence to run arbitrary perl,
                # then this whole thing can be retried
                status "couldn't pair $short with host; not syncing it";
                my $acknowledged = $term->ask_yn(
                                                 prompt => "Acknowledged?",
                                                 default => 'y',
                                                );
            }
        } else {
            $seq->add_should_succeed("git fetch origin '+refs/heads/*:refs/heads/*' --tags --no-prune");
            $seq->run();
        }
    } else {                    # repo new to this drive
        if ($annex) {
            mkdir "$dest" unless ( -d $dest );
            local $CWD = $dest;
            # bare repos don't get a reflog by default
            system "git -c core.logAllRefUpdates=true clone --bare $long $short";
            {
                local $CWD = $dir;
                system "git annex init '$short_drive_name'";
                system "git config annex.diskreserve '2GB'";
                # only set preferred content settings on a first init,
                # so that the user can override for this particular
                # backup drive
                system "git annex wanted . standard";
                system "git annex group . incrementalbackup";
                # TODO ask user before pairing since it's a guess
                if ( my $host_repo = find_host_annex($vshort) ) {
                    status "pairing $short with $host_repo";
                    local $CWD = $host_repo;
                    system "git remote add $short_drive_name $dir 2>/dev/null" || 1;
                    $seq->add_should_succeed("git annex sync --content $short_drive_name");
                    $seq->run();
                    # TODO now metadata sync with origin remote, if it exists
                } else {
                    status "couldn't pair $short with host; not syncing it";
                    my $acknowledged = $term->ask_yn(
                                                     prompt => "Acknowledged?",
                                                     default => 'y',
                                                    );
                }
            }
        } else {
            mkdir "$dest" unless ( -d $dest );
            local $CWD = $dest;
            # bare repos don't get a reflog by default
            $seq->add_should_succeed("git -c core.logAllRefUpdates=true clone --mirror $long $short");
            $seq->run;
        }
    }

    # Protect our backup from being reaped by git-gc
    {
        local $CWD = $dir;
        # Enable the reflog, since it is off by default in bare repos.
        # Since we fetch with --no-prune, no reflogs will ever get
        # deleted, so we have one for every branch that ever existed
        # in the remote we're backing up (that existed at a time we
        # ran this script, at least)
        system "git config core.logAllRefUpdates true";
        # Never remove reflog entries
        system "git config gc.reflogExpire never";
        # git-gc will never remove dangling commits mentioned in any
        # reflog *unless* they are unreachable in the branch the
        # reflog logs and are older than this config variable
        system "git config gc.reflogExpireUnreachable never";
        # avoid backing up broken commits
        system "git config fetch.fsckObjects true";
    }
}

sub find_host_annex {
    my $annex = shift;
    $annex =~ s|\.git$||;

    # parse output of `mr list`
    my @my_repos = split /^/, `mr -d $ENV{HOME} list`;
    @my_repos = apply { s/mr list:// } @my_repos;
    @my_repos = apply { $_ =~ s/^\s+|\s+$//g } @my_repos;
    @my_repos = grep { /^\// } @my_repos;

    # TODO check if they have any commits in common
    my @found = grep { $_ =~ /\/$annex$/ } @my_repos;
    return $found[0] if ( scalar @found == 1 );
}
