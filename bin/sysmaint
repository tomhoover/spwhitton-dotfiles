#!/usr/bin/perl

# This is meant to walk me through maintenance tasks that
# can't/shouldn't happen unattended by means of Propellor and/or cron
# jobs installed by Propellor.
#
# That includes, at least:
#
# - apt upgrades of bare metal hosts (other than automatic security
#   upgrades)
#
# - checking in and backing up homedirs, which I need to do on all
#   machines, not just those for which I am root
#
# - cleaning up temporary files
#
# - backups to devices usually kept offline
#
# Assumptions we make:
#
# - Each offline backup drive I use has a unique filesystem label.
#   This means that exactly one drive will ever be mounted to
#   /media/$USER/$foo on a given machine.
#
# Other notes:
#
# - If this script dies, it should be possible to just run it again
#   from the beginning.

use strict;
use warnings;
use lib "$ENV{HOME}/lib/perl5";
no warnings "experimental::smartmatch";

use Dpkg::Version;
use Term::UI;
use File::Which;
use ShellSequence;
use ScriptStatus;
use File::Grep "fgrep";
use File::Basename;
use File::chdir;
use Capture::Tiny qw/capture_merged capture/;
use List::MoreUtils "apply";
use File::Spec::Functions "rel2abs";
use Switch;

# ---- globals

my $seq = ShellSequence->new();
my $term = Term::ReadLine->new('brand');
my $host = `hostname -f`;

# ---- config

# where are our git repos?  a host defined in ~/.ssh/config
our $git_host = "athena";

# on the $git_host, where are our repositories?
our $git = "/srv/git/repositories";

# on the $git_host, where are our git-remote-gcrypt repos?
# (we have them in a separate dir because we use exclusively gcrypt's
# rsync mode.  otherwise, if mixed in with regular git repos, gcrypt
# has a --check option)
our $gcrypt = "/srv/gcrypt";

# annexes that should be inited on the backup drive, and synced with
# the corresponding annex in $HOME.  This list is manually maintained
# because I do not want this script to run `git annex init` in lots of
# repos, creating bogus UUIDs
my @annexes = qw/annex.git wikiannex.git dionysus.git/;

# hosts configuration
#
# This config is meant to set the contents of three variables, the
# default values and meanings of which are:
#
# - $can_sudo = 0;            whether we can become root using sudo(1) on this host
# - $can_push = 1;            whether we can push any of our git repos in $HOME to
#                             their origin remotes (if can push some, set to '1'
#                             and use .mrconfig to avoid trying to push the others)
# - $check_for_extdrive = 0;  whether we should expect to have an
#                             external drive plugged in and referenced on the
#                             command line

our $can_sudo = 0;
our $can_push = 1;
our $check_for_extdrive = 0;
switch ("$ENV{USER}\@$host") {
    case /^root@/                     { $can_sudo = 1; $can_push = 0; last }
    case /^spw@.*\.silentflame\.com$/ { $can_push = 0; last } # develacc
    case /\.silentflame\.com$/        { $can_sudo = 1; next }
    case /iris\.silentflame\.com$/    { $check_for_extdrive = 1; next }
    case /zephyr\.silentflame\.com$/  { $check_for_extdrive = 1; next }
}

# ---- prep

chdir $ENV{HOME};
my ($loc, $drive_name, $short_drive_name);

my @ARGV_positional = grep { $_ !~ m/^--/ } @ARGV;
my @ARGV_options = grep { $_ =~ m/^--/ } @ARGV;

if (@ARGV_positional) {
    $loc = rel2abs(shift @ARGV_positional);
    $drive_name = $loc;
    $short_drive_name = basename $drive_name;

    my @mountpoints = split /^/, `mount | cut -d' ' -f3`;
    @mountpoints = apply { $_ =~ s/^\s+|\s+$//g } @mountpoints;

    die "$loc is not a directory" unless ( -d $loc );
    die "$drive_name is not a removable drive" unless ( $drive_name ~~ @mountpoints );

    if ( ! -d "$loc/gitbk" ) {
        status "it looks like you haven't backed up to this media before";
        my $create = $term->ask_yn(prompt => "Create a new backup repository at $loc/gitbk?");
        if ($create) {
            mkdir "$loc/gitbk"
              or die "couldn't create $loc/gitbk -- check permissions";
        } else {
            exit 1;
        }
    }
} elsif ($check_for_extdrive) {
    status "you didn't specify a drive to perform a coldbkup to as a command";
    status "line argument to this script";
    exit unless $term->ask_yn(
                              prompt => "Continue sysmaint without coldbkup?",
                              default => 'y',
                             );
}

User:

goto System if ("--skip-user" ~~ @ARGV_options
                || "--only-system" ~~ @ARGV_options);

# ---- pre-backup cleanup tasks

$seq->add_should_zero("ls tmp");
$seq->add_should_succeed("src-register-all");
$seq->run();

status "cleaning up ~/src";
clean_orig_tars();
unlink glob "src/*.dsc";
unlink glob "src/*.diff.gz";
unlink glob "src/*.upload";
unlink glob "src/*.inmulti";
unlink glob "src/*.changes";
unlink glob "src/*.deb";
unlink glob "src/*.build";
unlink glob "src/*.buildinfo";
unlink glob "src/*.debian.tar.*";
unlink glob "src/*[0-9].tar.*"; # native package generated tarballs
system "clean-patch-queues -y";

while (42) {
    my $output = capture_merged { find_dirty_src() };
    if (length $output) {
        status "the following files/repos in ~/src should be cleaned up:";
        print $output;
        my $again = $term->ask_yn(
                                  prompt => "Check for files in ~/src again?",
                                  default => 'y',
                                 );
        last unless $again;
    } else {
        last;
    }
}

$seq->add_should_succeed("ls local/big");
$seq->add_should_succeed("ls local/pub");
$seq->run();
$term->get_reply(
                 prompt => "Consider cleaning up/annexing files in these two dirs.",
                 default => 'okay',
                );
$seq->add_should_succeed("ls");
$seq->run();
$term->get_reply(
                 prompt => "Clean up any loose files, e.g. from sbuild runs.",
                 default => 'done',
                );

# ---- standard backup procedure

# run a restow to catch if we need to run `mr adopt`
$seq->add_should_succeed("mr -ms restow");
$seq->add_should_succeed("mr -ms autoci");
# `mr -ms isclean` checks for stuff to be checked in ...
$seq->add_should_succeed("mr -ms isclean");
$seq->add_should_succeed("mr -s up");
$can_push and $seq->add_should_succeed("mr -s push");
# ... then `mr -ms status` finds unpushed branches & stashes
$seq->add_should_zero("mr -ms status");

$seq->run();

# ---- backup to offline media ("coldbkup" was old script name)

# TODO error handling here: since we're not using $seq for everything
if ( defined $loc ) {

    # ---- github-backup
    # handed over to a cronjob on athena
    # {
    #     mkdir "$loc/gitbk/github" unless ( -d "$loc/gitbk/github" );
    #     local $CWD = "$loc/gitbk/github";
    #     # TODO should login to github API to work around rate limiting
    #     $seq->add_should_succeed("github-backup spwhitton");
    #     $seq->run();
    # }

    # ---- athena repos
    my $athena_git_repos = capture {
        system "ssh athena 'for d in $git/*.git $git/*/*.git; do echo \$d; done'";
    };
    my $athena_gcrypt_repos = capture {
        system "ssh athena 'for d in $gcrypt/*; do echo \$d; done'";
    };
    my @athena_git_repos = split /^/, $athena_git_repos;
    @athena_git_repos = apply { s|$git/|| } @athena_git_repos;
    my @athena_gcrypt_repos = split /^/, $athena_gcrypt_repos;
    @athena_gcrypt_repos = apply { s|$gcrypt/|| } @athena_gcrypt_repos;

    foreach my $repo ( @athena_git_repos ) {
        $repo =~ s/\n//g;

        backup_repo("git\@spwhitton.name:$repo", "athena");
    }

    foreach my $repo ( @athena_gcrypt_repos ) {
        $repo =~ s/\n//g;
        backup_repo("gcrypt::rsync://athena:/srv/gcrypt/$repo", "athena_gcrypt");
    }

    # ---- misc. repos

    # Debian packages I'm responsible for, and a few other Debian repos

    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/wiki.git", "alioth", "pkg-emacsen");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dh-elpa.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dh-make-elpa.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/yasnippet.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ebib.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-async.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-buttercup.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-highlight-indentation.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-noflet.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/epl.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/f-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/flx.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/flycheck.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/helm.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/let-alist.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/paredit-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/parsebib.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/perspective-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/pkg-info-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/popup-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/persp-projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/helm-projectile.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/rainbow-delimiters.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/seq-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/s-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dash-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/dash-functional-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/shut-up.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/smex.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ws-butler.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/zenburn-emacs.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/aggressive-indent-mode.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/ert-async-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/git-annex-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/debpaste-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/magit-annex.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/xml-rpc-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/wc-mode.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/deft.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/key-chord-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/paredit-everywhere.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/visual-regexp-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/pointback.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-openwith.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-world-time-mode.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/helm-dash.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/redtick.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/message-templ.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/esxml.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-db.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-kv.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/nov-el.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-emacsen/pkg/emacs-helm-ag.git", "alioth");
    backup_repo("https://salsa.debian.org/emacsen-team/queue-el", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/spinner-el", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/cider", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/helm", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/epl", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/deft", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/ebib", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/dh-make-elpa", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/nov-el", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/yasnippet-snippets", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/emacs-buttercup", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/dash-el", "salsa");
    backup_repo("https://salsa.debian.org/emacsen-team/redtick", "salsa");

    backup_repo("https://salsa.debian.org/haskell-team/git-annex", "salsa");

    backup_repo("https://anonscm.debian.org/git/pkg-mozext/classic-theme-restorer.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/keysnail.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/ublock-origin.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/y-u-no-validate.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/pkg-mozext/self-destructing-cookies.git", "alioth");
    backup_repo("https://anonscm.debian.org/git/collab-maint/mairix.git", "alioth");

    backup_repo("https://anonscm.debian.org/git/python-modules/packages/pytest-helpers-namespace.git", "alioth");

    backup_repo("https://anonscm.debian.org/git/dbnpolicy/policy.git", "alioth");
}

# TODO luksClose if necessary & umount
# system "sudo umount $loc";
status "info: you can unmount & eject $loc" if ( defined $loc );

# ---- local system maintenance

System:

exit unless $can_sudo;
exit if ("--skip-system" ~~ @ARGV_options);
exit if ("--only-user" ~~ @ARGV_options);

unless ("--only-system" ~~ @ARGV_options) {
    exit unless $term->ask_yn(
                          prompt =>
                          "Backups complete.  Perform local system maintainance?"
                         );
}

$seq->add_should_succeed("df -h");
$seq->run();
$term->get_reply(
                 prompt => "Confirm that host has enough disc space, or clean up some files.",
                 default => 'done',
                );

if ($host eq "athena") {
    $seq->add_should_succeed("uptime");
    $seq->run();
    $term->get_reply(
                     prompt => "If athena was rebooted, perform athena reboot procedure.",
                     default => 'done',
                    );
}

# clean packages installed by mk-build-deps(1)
$seq->add_should_succeed("sudo aptitude remove '~n-build-deps\$'");

$seq->add_should_succeed("sudo apt-get update");
$seq->add_should_succeed("sudo apt-get upgrade");
$seq->add_should_succeed("sudo apt-get dist-upgrade");
$seq->add_should_succeed("sudo apt-get -y autoremove");
$seq->add_should_succeed("sudo apt-get autoclean");

which 'mailq' and $seq->add_should_zero("mailq | grep -v 'Mail queue is empty'");
$seq->run();

$seq->add_should_succeed("dpkg -l | awk '/^rc/ { print \$2 }'");
$seq->run();
$term->get_reply(
                 prompt => "If packages shown, consider `apt-get purge \$(dpkg -l | awk '/^rc/ { print \$2 }')`",
                 default => 'okay',
                );

$seq->add_should_succeed("aptitude search ?obsolete || true");
$seq->run();
$term->get_reply(
                 prompt => "If packages shown, consider removing no longer available from the mirrors: `aptitude purge ?obsolete`",
                 default => 'okay',
                );

$seq->add_should_succeed("dpkg-query -W '-f=\${Package}\\n\${Conffiles}\\n' | awk '/^[^ ]/{pkg=\$1}/ obsolete\$/{print pkg,\$0}'");
$seq->run();
$term->get_reply(
                 prompt => "If output, consider deleting these obsolete conffiles and then reinstalling packages providing them.",
                 default => 'okay',
                );

# ---- subroutines

sub clean_orig_tars {
    my $origs = {};
    foreach my $f ( glob "src/*.orig.tar.*" ) {
        $f =~ m/src\/([^_]*)_/;
        push @{$origs->{"$1"}}, $f;
    }
    sub orig_ver {
        $a =~ m/src\/[^_]*_([^_]*).orig/;
        my $ver_a = Dpkg::Version->new("$1");
        $b =~ m/src\/[^_]*_([^_]*).orig/;
        my $ver_b = Dpkg::Version->new("$1");
        $a cmp $b;
    }
    foreach my $pkg (keys %$origs) {
        my @origs = sort orig_ver @{$origs->{$pkg}};
        if ( -d "src/$pkg/.git" ) {
            if ( scalar @origs > 2 ) {
                @origs = splice @origs, 0, -2;
            } else {
                @origs = ();
            }
        }
        foreach my $orig ( @origs ) {
            unlink $orig;
        }
    }
}

sub find_dirty_src {
    foreach my $f ( glob "src/*" ) {
        my $short = basename($f);
        unless ( (-f $f && $f =~ /orig\.tar/)
                 # also permit symlinks to orig tarballs
                 || (-l $f && $f =~ /orig\.tar/)
                 # also permit gbp orig tarballs
                 || ($f =~ /orig\.gbp\.tar/)
                 || -d "$f/.git" || -d "$f/.hg" # handled by src-register-all
               ) {
            print "$f\n";
        }
    }
}

sub backup_repo {
    my ( $long, $dest, $rename ) = @_;
    my $short;

    # flush the command sequencer
    $seq->run();
    # third param is optional: do we need to rename it because
    # remote's name is too generic (e.g. 'wiki')?
    if ( defined $rename ) {
        $short = $rename;
    } else {
        if ( $long =~ m/^http/ ) {
            ( undef, $short ) = split /\/([^\/]+)$/, $long;
        } else {
            ( undef, $short ) = split /:([^:]+)$/, $long;
        }
        $short =~ s/\/srv\/(git|gcrypt)\///;
    }

    $short = "$short.git" unless $short =~ /\.git$/;
    my $vshort = basename $short;
    $dest = "$loc/gitbk/$dest";
    my $dir = "$dest/$short";
    status "backup source: $long";
    status "backup dest:   $dir";

    # first we have to determine whether it's an annex, as that will
    # affect the commands we run both to clone and to update
    # TODO determine this with a script?
    my $annex = 0;
    if ( $dest eq "$loc/gitbk/athena" && $vshort ~~ @annexes ) {
        $annex = 1;
    }

    if ( -e $dir ) {            # repo already backed up to this drive
        local $CWD = $dir;
        # TODO second disjunct in to allow for non-bare repos on
        # backup drive, e.g. gitbk/athena/annex on m3.  At present,
        # gitbk/athena/annex.git is a symlink to gitbk/athena/annex.
        # We should be able to handle this without the symlink, in
        # this script
        if ( -d "annex" || -d ".git/annex" ) {
            system "git config annex.diskreserve '2GB'";
            # TODO ask user before pairing since it's a guess
            if ( my $host_repo = find_host_annex($vshort) ) {
                status "pairing $short with $host_repo";
                local $CWD = $host_repo;
                system "git remote add $short_drive_name $dir 2>/dev/null" || 1;
                $seq->add_should_succeed("git annex sync --content $short_drive_name");
                $seq->run();
                # TODO now metadata sync with origin remote, if it exists
            } else {
                # TODO extend ShellSequence to run arbitrary perl,
                # then this whole thing can be retried
                status "couldn't pair $short with host; not syncing it";
                my $acknowledged = $term->ask_yn(
                                                 prompt => "Acknowledged?",
                                                 default => 'y',
                                                );
            }
        } else {
            # TODO verify origin remote is what we expect, or error
            # out: user probably needs to update backup drive layout
            $seq->add_should_succeed("git fetch origin '+refs/heads/*:refs/heads/*' --tags --no-prune");
            $seq->run();
        }
    } else {                    # repo new to this drive
        if ($annex) {
            mkdir "$dest" unless ( -d $dest );
            local $CWD = $dest;
            # bare repos don't get a reflog by default
            system "git -c core.logAllRefUpdates=true clone --bare $long $short";
            {
                local $CWD = $dir;
                system "git annex init '$short_drive_name'";
                system "git config annex.diskreserve '2GB'";
                # only set preferred content settings on a first init,
                # so that the user can override for this particular
                # backup drive
                system "git annex wanted . standard";
                system "git annex group . incrementalbackup";
                # TODO ask user before pairing since it's a guess
                if ( my $host_repo = find_host_annex($vshort) ) {
                    status "pairing $short with $host_repo";
                    local $CWD = $host_repo;
                    system "git remote add $short_drive_name $dir 2>/dev/null" || 1;
                    $seq->add_should_succeed("git annex sync --content $short_drive_name");
                    $seq->run();
                    # TODO now metadata sync with origin remote, if it exists
                } else {
                    status "couldn't pair $short with host; not syncing it";
                    my $acknowledged = $term->ask_yn(
                                                     prompt => "Acknowledged?",
                                                     default => 'y',
                                                    );
                }
            }
        } else {
            mkdir "$dest" unless ( -d $dest );
            local $CWD = $dest;
            # bare repos don't get a reflog by default
            $seq->add_should_succeed("git -c core.logAllRefUpdates=true clone --mirror $long $short");
            $seq->run;
        }
    }

    # Protect our backup from being reaped by git-gc
    {
        local $CWD = $dir;
        # Enable the reflog, since it is off by default in bare repos.
        # Since we fetch with --no-prune, no reflogs will ever get
        # deleted, so we have one for every branch that ever existed
        # in the remote we're backing up (that existed at a time we
        # ran this script, at least)
        system "git config core.logAllRefUpdates true";
        # Never remove reflog entries
        system "git config gc.reflogExpire never";
        # git-gc will never remove dangling commits mentioned in any
        # reflog *unless* they are unreachable in the branch the
        # reflog logs and are older than this config variable
        system "git config gc.reflogExpireUnreachable never";
        # avoid backing up broken commits
        system "git config fetch.fsckObjects true";
    }
}

sub find_host_annex {
    my $annex = shift;
    $annex =~ s|\.git$||;

    # parse output of `mr list`
    my @my_repos = split /^/, `mr -d $ENV{HOME} list`;
    @my_repos = apply { s/mr list:// } @my_repos;
    @my_repos = apply { $_ =~ s/^\s+|\s+$//g } @my_repos;
    @my_repos = grep { /^\// } @my_repos;

    # TODO check if they have any commits in common
    my @found = grep { $_ =~ /\/$annex$/ } @my_repos;
    return $found[0] if ( scalar @found == 1 );
}
