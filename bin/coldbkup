#!/bin/bash

# backup to removable, offline media

. $HOME/.shenv
. $HOME/lib/tputfs.sh

set -e

# TODO syncing annexes should be more systematic.  This first part of
# the script is the worst.  Detect if a git repo is an annex, and do
# some sensible backup sync.  So that, like with regular git repos,
# coldbkup can also set up a new backup drive without me having to do
# a lot of annex setting up (maybe a function: gitannexbk, or just
# auto-detect (better)).  We can init the annex and put it in the
# archive or backup group so we get a sensible default preferred
# content expression

# determine removable media available and if it's m3, sync annex content
# TODO do this by looking at size of removable media?
if mount | grep -q "/media/${USER}/m3"; then
    HDD=/media/${USER}/m3
    status syncing annex content
    # we sync both ma and m3 here so that ma knows everything that got
    # put onto m3
    cd $HOME/lib/annex
    git annex sync --content origin m3
    cd $HOME/lib/wikiannex
    git annex sync --content origin athena m3
    # TODO
    # cd $HOME/lib/dionysus
    # git annex sync --content m3
    cd $HOME
elif mount | grep -q "/media/${USER}/bkupsd"; then
    HDD=/media/${USER}/bkupsd

    status syncing wikiannex content
    cd $HOME/lib/wikiannex
    git annex sync --content origin athena bkupsd

    status syncing dionysus annex content
    cd $HOME/lib/dionysus
    git annex sync --content origin athena bkupsd
    cd $HOME
else
    echo "coldbkup: removable media not mounted" >&2
    exit 1
fi
DEST=${HDD}/git
mkdir -p $DEST

# function to backup a repo: first arg is ssh path to repo, second arg
# is where to put it
gitbk ()
{
    local long=$1
    local short=$(basename $long)
    local dest=$2
    if [ -e "$dest/$short" ]; then
        cd $dest/$short
        git fetch origin "+refs/heads/*:refs/heads/*" --prune --tags
    else
        mkdir -p $dest
        cd $dest
        git clone --mirror $long $short
    fi
}

# backup a repo from github
githubbk ()
{
    status processing $1 from github
    gitbk git@github.com:$1 $DEST/github
}

# backup a repo from alioth
aliothbk ()
{
    status processing $1 from alioth
    gitbk alioth:/git/$1 $DEST/alioth
}

# Stage 1 : Backup repos hosted on athena

# TODO: don't use ls here (see http://mywiki.wooledge.org/ParsingLs)

repos=$(ssh athena ls /home/git)
for repo in $repos; do
    status processing $repo from athena
    # TODO look in git-remote-gcrypt to find how it detects a gcrypt
    # repo; there must be a way
    if [ "$repo" = "priv.git" -o "$repo" = "annex.git" -o "$repo" = "rt.git" ]; then
        # might need a ssh:// and a /~/ in here to work with gcrypt
        gitbk gcrypt::git@spwhitton.name:/home/git/$repo $DEST/athena
    else
        gitbk git@spwhitton.name:/home/git/$repo $DEST/athena
    fi
done

# Stage 2 : Debian repos

aliothbk pkg-emacsen/pkg/aggressive-indent-mode.git
aliothbk pkg-emacsen/pkg/f-el.git
aliothbk pkg-emacsen/pkg/emacs-async.git
aliothbk pkg-emacsen/pkg/emacs-noflet.git
aliothbk pkg-emacsen/pkg/perspective-el.git
aliothbk pkg-emacsen/pkg/helm.git
aliothbk pkg-emacsen/pkg/epl.git
aliothbk pkg-emacsen/pkg/pkg-info-el.git
aliothbk pkg-emacsen/pkg/flx.git
aliothbk pkg-emacsen/pkg/projectile.git
aliothbk pkg-emacsen/pkg/let-alist.git
aliothbk pkg-emacsen/pkg/seq-el.git
aliothbk pkg-emacsen/pkg/shut-up.git
aliothbk pkg-emacsen/pkg/popup-el.git
aliothbk pkg-emacsen/pkg/paredit-el.git
aliothbk pkg-mozext/ublock-origin.git
aliothbk pkg-mozext/y-u-no-validate.git
aliothbk pkg-mozext/classic-theme-restorer.git
aliothbk pkg-emacsen/pkg/flycheck.git
aliothbk pkg-mozext/keysnail.git

# Stage 3 : Starred repos on github

# TODO Commented as downloading so many forks will be slow.  Maybe run
# it on athena instead?

# (
#     cd $DEST/github
#     github-backup spwhitton
# )
